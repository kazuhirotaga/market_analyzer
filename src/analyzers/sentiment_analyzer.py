"""ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ—¥æœ¬èªFinBERT (finance-sentiment-ja-base) ã‚’ä½¿ç”¨ã—ã¦
ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’åˆ†æã™ã‚‹ã€‚
"""

import logging
import math
from datetime import datetime, timedelta
from typing import Optional

from src.config import config
from src.database.models import get_session, NewsArticle, NewsTickerLink

logger = logging.getLogger(__name__)

# FinBERTãƒ¢ãƒ‡ãƒ« (é…å»¶ãƒ­ãƒ¼ãƒ‰)
_model = None
_tokenizer = None
_current_market_model = None  # ç¾åœ¨ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¸‚å ´ ("JP" or "US")


def _load_model():
    """FinBERTãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶ãƒ­ãƒ¼ãƒ‰"""
    global _model, _tokenizer, _current_market_model
    if _model is not None:
        return

    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        import torch

        if config.market == "US":
            model_name = "ProsusAI/finbert"
            _current_market_model = "US"
        else:
            model_name = "izumi-lab/bert-small-japanese-fin"
            _current_market_model = "JP"
            
        logger.info(f"ğŸ”„ ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_name}")

        _tokenizer = AutoTokenizer.from_pretrained(model_name)
        _model = AutoModelForSequenceClassification.from_pretrained(model_name)
        _model.eval()

        logger.info("âœ… ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
    except Exception as e:
        logger.error(f"âŒ ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        logger.info("ğŸ’¡ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã‚’ä½¿ç”¨ã—ã¾ã™")


class SentimentAnalyzer:
    """ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã‚¯ãƒ©ã‚¹"""

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾æ›¸
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾æ›¸
    POSITIVE_KEYWORDS_JP = [
        "ä¸Šæ˜‡", "å¢—å", "å¢—ç›Š", "å¥½èª¿", "å …èª¿", "ä¸Šæ–¹ä¿®æ­£", "æœ€é«˜ç›Š",
        "å¢—é…", "å›å¾©", "æˆé•·", "æ‹¡å¤§", "æ”¹å–„", "è²·ã„", "å¼·æ°—",
        "ãƒ—ãƒ©ã‚¹", "æ€¥é¨°", "é«˜å€¤", "å¤§å¹…å¢—", "é»’å­—", "å¥½æ±ºç®—",
    ]

    NEGATIVE_KEYWORDS_JP = [
        "ä¸‹è½", "æ¸›å", "æ¸›ç›Š", "ä¸æŒ¯", "è»Ÿèª¿", "ä¸‹æ–¹ä¿®æ­£", "èµ¤å­—",
        "æ¸›é…", "æ‚ªåŒ–", "ç¸®å°", "ä½è¿·", "å£²ã‚Š", "å¼±æ°—", "ãƒªã‚¹ã‚¯",
        "ãƒã‚¤ãƒŠã‚¹", "æ€¥è½", "å®‰å€¤", "å¤§å¹…æ¸›", "æå¤±", "æ‚ªæ±ºç®—",
        "ç ´ç¶»", "å€’ç”£", "ä¸æ­£", "æ’¤é€€", "ãƒªã‚¹ãƒˆãƒ©",
    ]

    POSITIVE_KEYWORDS_US = [
        "up", "rise", "gain", "growth", "jump", "surge", "climb", "rally",
        "profit", "positive", "bull", "bullish", "record", "beat", "strong",
        "upgrade", "buy", "dividend", "revenue up", "outperform"
    ]

    NEGATIVE_KEYWORDS_US = [
        "down", "fall", "drop", "decline", "slide", "crash", "plunge", "loss",
        "negative", "bear", "bearish", "miss", "weak", "downgrade", "sell",
        "cut", "revenue down", "underperform", "risk", "debt", "bankrupt"
    ]

    def __init__(self):
        self.use_model = False
        
        # å¸‚å ´ã«å¿œã˜ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®š
        if config.market == "US":
            self.POSITIVE_KEYWORDS = self.POSITIVE_KEYWORDS_US
            self.NEGATIVE_KEYWORDS = self.NEGATIVE_KEYWORDS_US
        else:
            self.POSITIVE_KEYWORDS = self.POSITIVE_KEYWORDS_JP
            self.NEGATIVE_KEYWORDS = self.NEGATIVE_KEYWORDS_JP

        try:
            _load_model()
            self.use_model = _model is not None
        except Exception:
            pass

    def analyze_text(self, text: str) -> dict:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’åˆ†æ

        Returns:
            {
                "score": float (-1.0 ã€œ 1.0),
                "label": str ("positive", "neutral", "negative"),
                "confidence": float (0.0 ã€œ 1.0),
                "method": str ("finbert" or "keyword")
            }
        """
        if not text or not text.strip():
            return {"score": 0.0, "label": "neutral", "confidence": 0.0, "method": "none"}

        if self.use_model:
            return self._analyze_with_model(text)
        else:
            return self._analyze_with_keywords(text)

    def analyze_articles(self, articles: list[dict] | None = None) -> list[dict]:
        """è¤‡æ•°è¨˜äº‹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’ä¸€æ‹¬åˆ†æã—ã¦DBã«ä¿å­˜

        Args:
            articles: åˆ†æå¯¾è±¡ã®è¨˜äº‹ãƒªã‚¹ãƒˆã€‚Noneã®å ´åˆã¯DBã‹ã‚‰æœªåˆ†æã®è¨˜äº‹ã‚’å–å¾—ã€‚

        Returns:
            åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
        """
        session = get_session()
        results = []

        try:
            if articles is None:
                # DBã‹ã‚‰æœªåˆ†æã®è¨˜äº‹ã‚’å–å¾—
                rows = (
                    session.query(NewsArticle)
                    .filter(NewsArticle.sentiment_score.is_(None))
                    .order_by(NewsArticle.published_at.desc())
                    .limit(200)
                    .all()
                )
            else:
                # æ¸¡ã•ã‚ŒãŸè¨˜äº‹ãƒªã‚¹ãƒˆã‹ã‚‰å¯¾å¿œã™ã‚‹DBè¡Œã‚’å–å¾—
                titles = [a.get("title", "") for a in articles if a.get("title")]
                rows = (
                    session.query(NewsArticle)
                    .filter(NewsArticle.title.in_(titles))
                    .all()
                )

            for row in rows:
                text = f"{row.title} {row.content or ''}"
                result = self.analyze_text(text)

                # DBæ›´æ–°
                row.sentiment_score = result["score"]
                row.confidence = result["confidence"]
                row.model_used = result["method"]

                results.append({
                    "article_id": row.id,
                    "title": row.title,
                    **result,
                })

            session.commit()
            logger.info(f"ğŸ§  ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æå®Œäº†: {len(results)} ä»¶")

        except Exception as e:
            session.rollback()
            logger.error(f"âŒ ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            raise
        finally:
            session.close()

        return results

    def get_ticker_sentiment(
        self,
        ticker: str,
        days: int | None = None,
    ) -> dict:
        """ç‰¹å®šéŠ˜æŸ„ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—

        Args:
            ticker: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (ä¾‹: "6758.T")
            days: å¯¾è±¡æ—¥æ•°ï¼ˆNoneã®å ´åˆã¯configè¨­å®šå€¤ã‚’ä½¿ç”¨ï¼‰

        Returns:
            {
                "ticker": str,
                "sentiment_score": float (-1.0 ã€œ 1.0),
                "article_count": int,
                "positive_count": int,
                "negative_count": int,
                "neutral_count": int,
                "latest_articles": list
            }
        """
        if days is None:
            days = config.sentiment_window_days

        session = get_session()
        try:
            cutoff = datetime.utcnow() - timedelta(days=days)

            # éŠ˜æŸ„ã«ç´ä»˜ã„ãŸè¨˜äº‹ã‚’å–å¾—
            rows = (
                session.query(NewsArticle)
                .join(NewsTickerLink, NewsArticle.id == NewsTickerLink.article_id)
                .filter(NewsTickerLink.ticker == ticker)
                .filter(NewsArticle.published_at >= cutoff)
                .filter(NewsArticle.sentiment_score.isnot(None))
                .order_by(NewsArticle.published_at.desc())
                .all()
            )

            if not rows:
                # éŠ˜æŸ„ç´ä»˜ã‘ãŒãªã„å ´åˆã€éŠ˜æŸ„åã§ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢
                stock_name = self._get_stock_name(session, ticker)
                if stock_name:
                    rows = (
                        session.query(NewsArticle)
                        .filter(NewsArticle.published_at >= cutoff)
                        .filter(NewsArticle.sentiment_score.isnot(None))
                        .filter(NewsArticle.title.contains(stock_name))
                        .order_by(NewsArticle.published_at.desc())
                        .limit(50)
                        .all()
                    )

            if not rows:
                return {
                    "ticker": ticker,
                    "sentiment_score": 0.0,
                    "article_count": 0,
                    "positive_count": 0,
                    "negative_count": 0,
                    "neutral_count": 0,
                    "latest_articles": [],
                }

            # æ™‚é–“æ¸›è¡°åŠ é‡å¹³å‡ã‚’è¨ˆç®—
            now = datetime.utcnow()
            decay = config.sentiment_decay_factor
            weighted_sum = 0.0
            weight_total = 0.0
            pos = neg = neu = 0

            for row in rows:
                if row.published_at:
                    days_ago = (now - row.published_at).total_seconds() / 86400
                else:
                    days_ago = days / 2  # æ—¥ä»˜ä¸æ˜ã¯ä¸­é–“ã«

                time_weight = math.pow(decay, days_ago)
                conf_weight = row.confidence if row.confidence else 0.5
                w = time_weight * conf_weight

                weighted_sum += row.sentiment_score * w
                weight_total += w

                if row.sentiment_score > 0.1:
                    pos += 1
                elif row.sentiment_score < -0.1:
                    neg += 1
                else:
                    neu += 1

            avg_score = weighted_sum / weight_total if weight_total > 0 else 0.0

            latest = [{
                "title": r.title,
                "sentiment": r.sentiment_score,
                "date": r.published_at.isoformat() if r.published_at else None,
            } for r in rows[:5]]

            return {
                "ticker": ticker,
                "sentiment_score": round(avg_score, 4),
                "article_count": len(rows),
                "positive_count": pos,
                "negative_count": neg,
                "neutral_count": neu,
                "latest_articles": latest,
            }
        finally:
            session.close()

    # --- Private Methods ---

    def _analyze_with_model(self, text: str) -> dict:
        """FinBERTãƒ¢ãƒ‡ãƒ«ã§ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ"""
        # ãƒ¢ãƒ‡ãƒ«ã®å‹•çš„ãƒªãƒ­ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        global _model, _tokenizer, _current_market_model

        target_model = "US" if config.market == "US" else "JP"
        
        # ç¾åœ¨ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¸‚å ´ã¨ç•°ãªã‚‹å ´åˆã¯ãƒªãƒ­ãƒ¼ãƒ‰
        if _current_market_model != target_model:
            logger.info(f"ğŸ”„ å¸‚å ´å¤‰æ›´æ¤œçŸ¥ ({_current_market_model} -> {target_model}): ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¾ã™")
            _model = None
            _tokenizer = None
            _load_model()

        if _model is None:
            return self._analyze_with_keywords(text)

        import torch

        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ€å¤§512ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ¶é™
            inputs = _tokenizer(
                text, return_tensors="pt",
                truncation=True, max_length=512, padding=True
            )

            with torch.no_grad():
                outputs = _model(**inputs)
                probs = torch.softmax(outputs.logits, dim=-1)[0]

            # ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ™ãƒ«é †åºã«å¿œã˜ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
            labels = _model.config.id2label
            scores_dict = {}
            for idx, label_name in labels.items():
                scores_dict[label_name.lower()] = float(probs[idx])

            # ã‚¹ã‚³ã‚¢è¨ˆç®—
            pos = scores_dict.get("positive", 0)
            neg = scores_dict.get("negative", 0)
            neu = scores_dict.get("neutral", 0)

            score = pos - neg  # -1.0 ã€œ 1.0
            confidence = max(pos, neg, neu)

            if pos > neg and pos > neu:
                label = "positive"
            elif neg > pos and neg > neu:
                label = "negative"
            else:
                label = "neutral"

            return {
                "score": round(score, 4),
                "label": label,
                "confidence": round(confidence, 4),
                "method": "finbert",
            }
        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«åˆ†æå¤±æ•—ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")
            return self._analyze_with_keywords(text)

    def _analyze_with_keywords(self, text: str) -> dict:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        # å¸‚å ´ã«å¿œã˜ã¦é©åˆ‡ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’é¸æŠ
        if config.market == "US":
            keywords_pos = self.POSITIVE_KEYWORDS_US
            keywords_neg = self.NEGATIVE_KEYWORDS_US
        else:
            keywords_pos = self.POSITIVE_KEYWORDS_JP
            keywords_neg = self.NEGATIVE_KEYWORDS_JP

        pos_count = sum(1 for kw in keywords_pos if kw in text)
        neg_count = sum(1 for kw in keywords_neg if kw in text)
        total = pos_count + neg_count

        if total == 0:
            return {"score": 0.0, "label": "neutral", "confidence": 0.3, "method": "keyword"}

        score = (pos_count - neg_count) / total
        confidence = min(0.8, total * 0.1)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã«å¿œã˜ãŸä¿¡é ¼åº¦

        if score > 0.1:
            label = "positive"
        elif score < -0.1:
            label = "negative"
        else:
            label = "neutral"

        return {
            "score": round(score, 4),
            "label": label,
            "confidence": round(confidence, 4),
            "method": "keyword",
        }

    def _get_stock_name(self, session, ticker: str) -> str | None:
        """éŠ˜æŸ„åã‚’å–å¾—"""
        from src.database.models import Stock
        stock = session.query(Stock).filter_by(ticker=ticker).first()
        return stock.name if stock else None
